# Storage Organization - Database IDs + Date Partitioning

## Overview

This document describes the semantic storage path strategy for video and audio files in Solo:Level. Files are organized using database IDs and date partitioning for improved debugging, lifecycle management, and storage operations at scale.

## Path Structure

### Videos (raw bucket)
```
{user_id}/videos/{yyyymmdd}/{video_recording_id}/video.{format}
```

**Example:**
```
488a7161-5d6e-4c4b-9a8e-12345678abcd/videos/20251014/1234/video.mp4
```

### Audio (processed bucket)
```
{user_id}/videos/{yyyymmdd}/{video_recording_id}/audio/{feedback_id}/{segment_index}.{format}
```

**Example:**
```
488a7161-5d6e-4c4b-9a8e-12345678abcd/videos/20251014/1234/audio/1069/0.wav
```

## Bucket Architecture

### Physical Separation
- **raw bucket:** Video files (private, authenticated users)
  - RLS: Users can read/write their own videos
  - Security: Client-side upload via signed URLs
  
- **processed bucket:** Generated audio files (private, service-role only)
  - RLS: Service-role only (no direct client access)
  - Security: Generated by Edge Functions, accessed via signed URLs

### Logical Grouping
- Both buckets use matching path prefixes: `{user_id}/videos/{yyyymmdd}/{video_id}/`
- Enables grouping-by-video while maintaining bucket-level security boundaries
- Date folders are consistent across buckets for lifecycle operations

## Benefits

### ðŸ” Debugging
- **See ID in path â†’ instant DB correlation:** `videos/20251014/1234/` tells you exactly which video_recording row to query
- **No timestamp lookups required:** Path contains database primary key, not anonymous milliseconds
- **Storage inspection:** Can navigate folders by date and ID in Supabase Storage dashboard

**Example:**
```sql
-- User reports issue with video from Oct 14
SELECT * FROM video_recordings WHERE id = 1234;
-- No need to convert timestamps or guess which file
```

### ðŸ—“ï¸ Data Lifecycle Management

#### Retention Policies
```sql
-- Delete all files from January 2024 (across both buckets)
DELETE FROM storage.objects 
WHERE name LIKE '%/videos/202401%' 
AND bucket_id IN ('raw', 'processed');
```

#### Archival Operations
```bash
# Move old date folders to cold storage (per bucket)
# Archive raw videos from Q1 2024
supabase storage download raw videos/20240101/ --output /archive/raw/
supabase storage download raw videos/20240102/ --output /archive/raw/
# ... repeat for processed bucket
```

#### Cleanup Scripts
```javascript
// Delete videos older than 90 days
const cutoffDate = new Date();
cutoffDate.setDate(cutoffDate.getDate() - 90);
const yyyymmdd = cutoffDate.toISOString().slice(0, 10).replace(/-/g, '');

// Query videos before cutoff
const { data } = await supabase
  .from('video_recordings')
  .select('storage_path')
  .lt('created_at', cutoffDate.toISOString());

// Delete from both buckets (raw + processed)
for (const video of data) {
  await supabase.storage.from('raw').remove([video.storage_path]);
  // Audio files stored in processed bucket with matching prefix
  const audioPrefix = video.storage_path.replace('/video.', '/audio/');
  await supabase.storage.from('processed').list(audioPrefix);
  // ... delete audio files
}
```

### ðŸ“Š Analytics & Monitoring

#### Storage Metrics by Month
```sql
-- Count files per month across buckets
SELECT 
  bucket_id,
  SUBSTRING(name, POSITION('videos/' IN name) + 7, 6) AS year_month,
  COUNT(*) AS file_count,
  SUM(metadata->>'size')::BIGINT AS total_bytes
FROM storage.objects
WHERE name LIKE '%/videos/%'
GROUP BY bucket_id, year_month
ORDER BY bucket_id, year_month DESC;
```

#### Growth Tracking
```javascript
// Monitor storage growth by date
const storageByDate = await supabase.rpc('get_storage_metrics_by_date', {
  bucket: 'raw',
  start_date: '20250101',
  end_date: '20251231'
});
```

### âš¡ Performance at Scale

#### Partitioned Listing
- **Without dates:** List entire user folder â†’ O(n) where n = all videos
- **With dates:** List specific date folder â†’ O(m) where m = videos that day
- **Impact:** 10x-100x faster for large user libraries

#### Faster Queries
```javascript
// Efficient: List videos from specific date
const { data } = await supabase.storage
  .from('raw')
  .list(`${userId}/videos/20251014/`);

// Inefficient (old approach): List all user videos, filter client-side
const { data } = await supabase.storage
  .from('raw')
  .list(`${userId}/`);
```

### ðŸ”’ Guaranteed Uniqueness
- Primary keys guarantee no path collisions
- No race conditions from timestamp-based naming
- Predictable storage structure

## Migration Strategy

### Phase 1: Add storage_path columns âœ…
- Added `storage_path` to `analysis_audio_segments`
- Backward compatible (NULL allowed)

### Phase 2: Update services to populate new paths âœ…
- Video upload uses `buildVideoPath()`
- Audio generation uses `buildAudioPath()`
- Both old and new fields populated during transition

### Phase 3: Client prefers storage_path âœ…
- Audio service generates signed URLs from `storage_path`
- Falls back to `audio_url` for old records
- Video service already uses `storage_path`

### Phase 4: Deprecate old fields (future)
- After migration period, make `storage_path` NOT NULL
- Remove `audio_url` column (kept only for legacy records)
- Update RLS policies if needed

## Operational Runbook

### Find all assets for a video
```sql
-- Get video storage path
SELECT storage_path FROM video_recordings WHERE id = 1234;
-- Returns: 488a7161.../videos/20251014/1234/video.mp4

-- List all audio for this video (in processed bucket)
SELECT storage_path FROM analysis_audio_segments
WHERE feedback_id IN (
  SELECT id FROM analysis_feedback
  WHERE analysis_id IN (
    SELECT id FROM analyses
    WHERE job_id IN (
      SELECT id FROM analysis_jobs WHERE video_recording_id = 1234
    )
  )
);
```

### Cleanup old videos and audio
```bash
#!/bin/bash
# cleanup-old-storage.sh
# Delete all files older than retention period

CUTOFF_DATE="20240101"  # yyyymmdd format

# Delete from raw bucket (videos)
supabase storage rm raw --recursive \
  --filter "created_at<${CUTOFF_DATE}" \
  --path "*/videos/*"

# Delete from processed bucket (audio)
supabase storage rm processed --recursive \
  --filter "created_at<${CUTOFF_DATE}" \
  --path "*/videos/*"
```

### Verify storage consistency
```sql
-- Find videos with missing storage files
SELECT vr.id, vr.storage_path
FROM video_recordings vr
LEFT JOIN storage.objects so ON so.name = vr.storage_path AND so.bucket_id = 'raw'
WHERE so.id IS NULL;

-- Find orphaned storage files (no DB record)
SELECT so.name
FROM storage.objects so
LEFT JOIN video_recordings vr ON vr.storage_path = so.name
WHERE so.bucket_id = 'raw'
  AND so.name LIKE '%/videos/%'
  AND vr.id IS NULL;
```

## Future Extensions

### Thumbnails
```
{user_id}/videos/{yyyymmdd}/{video_id}/thumbnail.jpg
```
Already implemented in Task 31 using separate `thumbnails` bucket.

### Pose Data
```
{user_id}/videos/{yyyymmdd}/{video_id}/pose.json
```
Logical location for pose detection results.

### Multiple Feedback Rounds
```
{user_id}/videos/{yyyymmdd}/{video_id}/audio/{feedback_id}/{segment_index}.wav
```
Already supports multiple feedback IDs per video.

## Related Files
- **Path Helpers:** `packages/api/src/services/storagePathHelpers.ts`
- **Video Upload:** `packages/api/src/services/videoUploadService.ts`
- **Audio Worker:** `supabase/functions/ai-analyze-video/workers/audioWorker.ts`
- **Audio Service:** `packages/api/src/services/audioService.ts`
- **Migration:** `supabase/migrations/20251021000000_optimize_storage_paths.sql`

